---
title: "HW 7 - Numerical Integration"
author: "Qinghua Li"
date: "3/25/2025"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Maximization of poisson GLMM from lecture

Now that we have discussed several approaches for numerical integration, lets now maximize the model given in lecture.  You may choose any maximization approach, as well as any numerical integration procedure from lecture, to obtain the MLE's for $\boldsymbol{\beta}$ and $\sigma_{\gamma}^2$.  

Hint: You should evaluate a number of intervals/nodes, decreasing the convergence threshold, etc and evaluate its impact before reporting your final result. We have shown how to perform, for example, AGQ and IS to obtain the likelihood pertaining to the first subject from class. 

```{r, warning=FALSE}
## Solution: place relevant helper functions pertaining to integration here 
library(statmod)
library(optimx)

# complete data likelihood i
ll_i = function(x, y, gammai) {
  val = rep(NA, length(gammai))
  for (i in 1:length(val)) {
    lambda = exp(x[1] + x[2] * 1:5 + gammai[i] * sqrt(2 * x[3]))
    val0 = dpois(y, lambda)
    val[i] = prod(val0) / (sqrt(pi))
  }
  return(val)
}

# likelihood i
int_i = function(x, y, M) {
  gh = gauss.quad(n = M, kind = "hermite")
  w = gh$weights
  g = gh$nodes
  val = sum(w * ll_i(x = x, y = y, gammai = g))
  return(val)
}

## End Solution



## Solution: place relevant helper functions pertaining to maximization here (likelihood etc)
logl = function(x, y, M) {
  val = rep(NA, length(y) / 5)
  for (i in 1:(length(y)/5)) {
    yi = y[(5*(i-1) + 1):(5*i)]
    val[i] = log(int_i(x, yi, M))
  }
  return(sum(val))
}

## End Solution



## Solution: place primary code for maximization here, calling functions in the above two sections
## Remember to print your primary results and use the following starting values
beta = c(1.804, 0.165)
s2gamma = 0.000225
alz = read.table("Data/alzheimers.dat", header = T)
M = 5
tol = 10^6
maxit = 1000
iter = 0
eps = Inf

fit = function(tol, M) {
  return(optimx(
    par = c(beta, s2gamma), 
    fn = function(x, y, M){-logl(x, y, M)},
    method = "L-BFGS-B",
    y = alz$words,
    M = M,
    upper = c(3, 3, 1),
    lower = c(-3, -3, 0),
    control = list(
      trace = 0,
      factr= tol
    )
  ))
}

fit(tol = 10^2, M = 100)

## End Solution
```

```{r, warning=FALSE}
fit(tol = 10^3, M = 100)
```


```{r, warning=FALSE}
ff <- fit(tol = 10^6, M = 100)
ff
```


```{r, warning=FALSE}
fit(tol = 10^6, M = 5)
```



# Plot

Now, plot the fitted line from the fitted GLMM on the spaghetti plot from lecture

```{r}
## solution
for (i in 1:max(alz$subject)) {
    # select subject indices
  index = which(alz$subject == i)
    
    # plot trajectory
  if (i == 1) {
    plot(
      alz$month[index],
      alz$words[index],
      type = 'l',
      ylim = range(alz$words),
      ylab = "Words",
      xlab = "Month",
      col = i
    )
  } else{
    lines(alz$month[index], alz$words[index], type = 'l', col = i)
    }
}
lines(1:5, exp(ff$p1 + ff$p2 * 1:5), type = 'l', lwd = 3)
## end solution
```